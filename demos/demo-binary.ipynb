{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contour Proposal Networks Ôºç How to detect objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "import celldetection as cd\n",
    "from celldetection import models, toydata\n",
    "import numpy as np\n",
    "import os\n",
    "from collections import OrderedDict\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "from torch.cuda.amp import GradScaler, autocast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Config\n",
    "You can save a config `conf.to_json(filename)` and load it with `cd.Config.from_json(filename)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = cd.Config(\n",
    "    # data\n",
    "    in_channels=3,\n",
    "    classes=2,\n",
    "    shuffle=True,\n",
    "    bg_fg_dists=(0.8, 0.85),\n",
    "    \n",
    "    # augmentation (schema: <class_name>:<kwargs>)\n",
    "    augmentation=OrderedDict({\n",
    "        'Transpose': {'p': 0.5},  # see: https://albumentations.ai/docs/\n",
    "        'RandomRotate90': {'p': 0.5},\n",
    "    }),\n",
    "    \n",
    "    # cpn\n",
    "    cpn='CpnU22',  # see https://git.io/JOnWX for alternatives\n",
    "    score_thresh=.9,\n",
    "    nms_thresh=.5,\n",
    "    contour_head_stride=8,\n",
    "    order=7,  # the higher, the more complex shapes can be detected\n",
    "    samples=128,  # number of coordinates per contour\n",
    "    refinement_iterations=3,\n",
    "    refinement_buckets=6,\n",
    "    inputs_mean=.5,\n",
    "    inputs_std=.5,\n",
    "    tweaks={\n",
    "        'BatchNorm2d': {'momentum': 0.05}\n",
    "    },\n",
    "    \n",
    "    # optimizer\n",
    "    optimizer={'Adadelta': {'lr': 1., 'rho': 0.9}},\n",
    "    scheduler={'StepLR': {'step_size': 5, 'gamma': .99}},\n",
    "    \n",
    "    # training\n",
    "    epochs=100,\n",
    "    steps_per_epoch=8 * 512,\n",
    "    batch_size=8,\n",
    "    amp=torch.cuda.is_available(),\n",
    "    \n",
    "    # misc\n",
    "    num_workers=0,\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    ")\n",
    "print(conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Toy Dataset\n",
    "Each item of the dataset consists of an image and a label image.\n",
    "Just put your label image into the `CPNTargetGenerator` via `gen.feed(labels=labels)` and it will generate training targets.\n",
    "\n",
    "If you do not have a label image, you might have one of those:\n",
    "- A list of masks, each mask shows a single object. Then you can use:\n",
    "```\n",
    "labels = cd.data.unary_masks2labels([mask1, mask2, ..., maskN])\n",
    "```\n",
    "- A list of masks, each mask may show multiple objects, but touching objects were assigned different numbers. Then you can use:\n",
    "```\n",
    "labels = cd.data.masks2labels([mask1, mask2, ..., maskN])\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self, samples, order, max_bg_dist, min_fg_dist, transforms=None, items=2**12):\n",
    "        self.gen = cd.data.CPNTargetGenerator(\n",
    "            samples=samples,\n",
    "            order=order,\n",
    "            min_fg_dist=min_fg_dist,\n",
    "            max_bg_dist=max_bg_dist,\n",
    "        )\n",
    "        self._items = items\n",
    "        self.transforms = transforms\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self._items\n",
    "    \n",
    "    @staticmethod\n",
    "    def map(image):\n",
    "        image = image / 255\n",
    "        return image\n",
    "    \n",
    "    @staticmethod\n",
    "    def unmap(image):\n",
    "        image = image * 255\n",
    "        image = np.clip(image, 0, 255).astype('uint8')\n",
    "        return image\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        img, _, labels, _ = cd.toydata.random_geometric_objects()\n",
    "        \n",
    "        if self.transforms is not None:\n",
    "            r = self.transforms(image=img, mask=labels)\n",
    "            img, labels = r['image'], r['mask']\n",
    "        \n",
    "        gen = self.gen\n",
    "        gen.feed(labels=labels)\n",
    "        \n",
    "        image = self.map(img)\n",
    "        return OrderedDict({\n",
    "            'inputs': image.astype('float32'),\n",
    "            'labels': gen.reduced_labels,\n",
    "            'fourier': (gen.fourier.astype('float32'),),\n",
    "            'locations': (gen.locations.astype('float32'),),\n",
    "            'sampled_contours': (gen.sampled_contours.astype('float32'),),\n",
    "            'sampling': (gen.sampling.astype('float32'),),\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = cd.conf2augmentation(conf.augmentation)\n",
    "train_data = Dataset(conf.samples, conf.order, *conf.bg_fg_dists, transforms=transforms, items=conf.steps_per_epoch)\n",
    "test_data = Dataset(conf.samples, conf.order, *conf.bg_fg_dists, items=2)\n",
    "train_loader = DataLoader(train_data, batch_size=conf.batch_size, num_workers=conf.num_workers,\n",
    "                          collate_fn=cd.universal_dict_collate_fn, shuffle=conf.shuffle)\n",
    "test_loader = DataLoader(test_data, batch_size=2, num_workers=0, collate_fn=cd.universal_dict_collate_fn)\n",
    "\n",
    "# Plot example\n",
    "example = train_data[0]\n",
    "contours = example['sampled_contours'][0]\n",
    "image = Dataset.unmap(example['inputs'])\n",
    "cd.vis.show_detection(image, contours=contours, contour_line_width=5, figsize=(11, 11))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. CPN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = getattr(models, conf.cpn)(in_channels=conf.in_channels, order=conf.order, samples=conf.samples,\n",
    "                                  refinement_iterations=conf.refinement_iterations, nms_thresh=conf.nms_thresh,\n",
    "                                  score_thresh=conf.score_thresh, contour_head_stride=conf.contour_head_stride,\n",
    "                                  classes=conf.classes, refinement_buckets=conf.refinement_buckets,\n",
    "                                  backbone_kwargs=dict(inputs_mean=conf.inputs_mean, inputs_std=conf.inputs_std))\n",
    "cd.conf2tweaks_(conf.tweaks, model)\n",
    "model.to(conf.device)\n",
    "optimizer = cd.conf2optimizer(conf.optimizer, model.parameters())\n",
    "scheduler = cd.conf2scheduler(conf.scheduler, optimizer)\n",
    "scaler = GradScaler() if conf.amp else None  # set None to disable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Training\n",
    "## 4.1 Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, train_loder, device, optimizer, epoch, scaler=None, scheduler=None):\n",
    "    model.train()\n",
    "    for batch_idx, batch in enumerate(tqdm(train_loader, desc=\"Epoch %d\" % epoch)):\n",
    "        batch = cd.to_device(batch, device)\n",
    "        optimizer.zero_grad()\n",
    "        with autocast(scaler is not None):\n",
    "            outputs = model(batch['inputs'], targets=batch)\n",
    "        loss = outputs['loss']\n",
    "        if scaler is None:\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        else:\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "    if scheduler is not None:\n",
    "        scheduler.step()\n",
    "\n",
    "def show_results(model, test_loader, device):\n",
    "    model.eval()\n",
    "    batch = cd.to_device(next(iter(test_loader)), device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(batch['inputs'])\n",
    "    o = cd.asnumpy(outputs)\n",
    "    num = len(o['contours'])\n",
    "    plt.figure(None, (13 * num, 13))\n",
    "    for idx in range(num):\n",
    "        image = cd.asnumpy(batch['inputs'][idx])\n",
    "        plt.subplot(1, num, idx + 1)\n",
    "        cd.vis.show_detection(Dataset.unmap(image.transpose(1, 2, 0)), contours=o['contours'][idx],\n",
    "                              contour_line_width=5, scores=o['scores'][idx])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1, conf.epochs):\n",
    "    train_epoch(model, train_loader, conf.device, optimizer, epoch, scaler, scheduler)\n",
    "    if epoch % 1 == 0:\n",
    "        show_results(model, test_loader, conf.device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
